---
layout: post
title: Distributed AI/ML model training on HPC clusters
description: This tutorial will cover the basic concepts and fundamentals of High Performance Computing (HPC), Artificial Intelligence (AI), why HPC is important for AI, and distributed training strategies with a focus on PyTorch Distributed Data Parallel (DDP). Through handson exercises, participants will learn step by step how to scale training from a single GPU to multiple GPUs on a single node, and finally extending to multi-node distributed environment.
date: 2025-10-25
event_time: "10:00 - 11ï¼š00 AM"        
event_date: "Oct 25, 2025"
category: agenda
author: zhenhua
image:
video_embed:
tags: [Online Agenda]
featured: false
toc: false
---

